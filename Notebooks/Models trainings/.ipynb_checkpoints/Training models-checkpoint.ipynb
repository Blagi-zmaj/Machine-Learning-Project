{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228901c8-af6b-475a-be65-8decdf5c8183",
   "metadata": {},
   "source": [
    "# Trenowanie modeli"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870481bd-52b4-45d2-a553-95892662df1e",
   "metadata": {},
   "source": [
    "## Pobieranie danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9eec5f-afa7-4eaf-a0d0-d6b29ba3e82d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edae730a-2a93-406e-8940-027ab085e054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_classified_title_only = pd.read_csv(\"skills_classified_title_only.csv\")\n",
    "# skills_classified_title_only.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a43390-8964-4dec-a103-0384739fe79e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_classified_title_only.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff5b7a3-05d6-4531-b326-52c1824cad42",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary = pd.read_csv(\"../Data analysis/../Data analysis/wszystkie_dane_tylko_z_salary.csv\")\n",
    "all_data_with_salary.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1520a4-f964-4dd1-a4a4-1f033051e963",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b53a134f-9662-41c2-ac0e-878bbde71a3a",
   "metadata": {},
   "source": [
    "## Przygotowanie danych"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fba429c-e6d2-4f41-b7ff-f38d7fff5f7b",
   "metadata": {},
   "source": [
    "### Delete hours from scraped_at"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185e2953-8efb-4757-b3e4-6f344b47e342",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data_with_salary.loc[:, \"scraped_at\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc134743-e866-4914-a198-01f05598ef81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data_with_salary.loc[:, \"scraped_at\"] = all_data_with_salary.loc[:, \"scraped_at\"].str.split(\" \").str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8ec20a-c055-4f52-892b-0956ecccc7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.loc[:, \"scraped_at\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356ed36e-59e3-4f10-9e04-9fa799b74242",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"2025-04-03 20:43:33 UTC\".split(\" \")[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca813cd-7d2d-44f7-8370-632976c08974",
   "metadata": {},
   "source": [
    "### all_data_with_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62a6f4e-58bc-41c4-a570-6283eb611c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45348aa3-e626-4d18-b01b-613e9bcc8489",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.columns[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aeb0642-9960-4911-9d31-24f00202c16b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.columns[12:14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef91ae-983d-4d35-a78c-7fd9f01fcdce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a0827b4-adde-4f99-bac3-7ea056a6f762",
   "metadata": {},
   "source": [
    "### Pogrupowanie danych według dat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df74359-b55b-4f77-a03c-ec62e3ad38e3",
   "metadata": {},
   "source": [
    "#### Count each skills and sort from most "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af661aaf-0e18-495f-b810-2461166e8550",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data_with_salary.loc[:, \".Net\":]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2ef6a7-34e2-4662-852b-793291c12410",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.iloc[:, 12:].apply(pd.Series.value_counts).sum(axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542f1a0a-3a80-4385-8145-5775cf0e0e63",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.iloc[:, 12:] == 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ffd7331-5bfe-471e-a5d7-414e44387c08",
   "metadata": {},
   "source": [
    "#### Find top 100 or less skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cd1b56-e790-4214-a1a3-befdeba14de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skills = (all_data_with_salary.iloc[:, 12:] == 1).sum().sort_values(ascending=False)\n",
    "top_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cefd46e-3685-4456-a104-00494162f352",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skills[top_skills > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "233a2ff8-182b-402c-ad0f-fd37c2012408",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skills.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df90801a-6ca6-42d6-bb37-69fe1b107d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(top_skills[top_skills > 8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cc05bd-7a7e-4e4a-8292-f78d187ce78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skills = top_skills[top_skills > 8].sort_values(ascending=False).head(100)\n",
    "top_skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc29dacc-c9c0-43f6-8fff-7c3c2479d75b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(top_skills.values)\n",
    "print(top_skills.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d93e308-31ca-4204-a2b2-2d140c964ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "top_skills.index\n",
    "top_skills_names = top_skills.index.tolist()\n",
    "top_skills_values = top_skills.values.tolist()\n",
    "print(top_skills_values)\n",
    "print(top_skills_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61fb3bb8-ad9d-4a5b-945e-fde42797cec0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05fd081e-cbfb-4b01-8ba1-e2a4c4c47052",
   "metadata": {},
   "source": [
    "#### Group by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fe88ef3-bf1f-46de-ab77-62b6f4f799b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[\"Python\"].count() # Count all rows (with 0 and 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bccc200b-3d53-48f6-816d-7ae5b97e3119",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[\"Python\"].sum() # Sum values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dbf205e-e9c4-43a9-8194-c1e491b083db",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[\"Python\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2623d87-9df4-4d8a-841d-bbcc63649b97",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[\"Python\"].apply(lambda x: (x == 1)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ee73df-abf6-431b-9a8d-4f199dc56957",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[\"Python\"].apply(lambda x: (x == 1).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e15c31-d958-435b-9358-31f595950a8e",
   "metadata": {},
   "source": [
    "##### Group all top skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b97c19-7925-410a-a8f3-81d97bdc5d2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.groupby(\"scraped_at\")[top_skills_names].apply(lambda x: (x == 1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c15146-6da1-415a-97c4-2c6bcf23429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cecf65d-05a9-40c0-ae2d-30edb2974d92",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_max_salary = all_data_with_salary.groupby([\"scraped_at\", \"experience\"])[\"max_salary\"].mean().reset_index()\n",
    "# print(grouped_max_salary)\n",
    "# print(grouped_max_salary[\"experience\"].unique())\n",
    "plt.figure(figsize=(14, 7))\n",
    "for seniority in grouped_max_salary[\"experience\"].unique():\n",
    "    print(seniority)\n",
    "    subset = grouped_max_salary[grouped_max_salary[\"experience\"] == seniority]\n",
    "    \n",
    "    plt.plot(subset[\"scraped_at\"], subset[\"max_salary\"], marker=\"o\")\n",
    "    plt.xticks(rotation=55)\n",
    "   \n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a552f34-6209-4471-870d-053ba96ff8ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = all_data_with_salary\n",
    "df['scraped_at'] = pd.to_datetime(df['scraped_at'])\n",
    "df = df.sort_values('scraped_at')\n",
    "daily_means = df.groupby('scraped_at')['min_salary'].mean().reset_index()\n",
    "daily_mins = df.groupby('scraped_at')['min_salary'].min().reset_index()\n",
    "daily_maxs = df.groupby('scraped_at')['min_salary'].max().reset_index()\n",
    "\n",
    "# print(daily_mins)\n",
    "# print(daily_maxs)\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(daily_means['scraped_at'], \n",
    "         daily_means['min_salary'], \n",
    "         marker='o', \n",
    "         linestyle='-', \n",
    "         color='navy',\n",
    "         label='Min mean salary')\n",
    "\n",
    "plt.plot(\n",
    "    daily_mins['scraped_at'],\n",
    "    daily_mins['min_salary'],\n",
    "    marker=\"o\",\n",
    "    linestyle='-',\n",
    "    color='red',\n",
    "    label='Min min salary'\n",
    ")\n",
    "\n",
    "plt.plot(\n",
    "    daily_maxs['scraped_at'],\n",
    "    daily_maxs['min_salary'],\n",
    "    marker=\"o\",\n",
    "    linestyle='-',\n",
    "    color='green',\n",
    "    label='Min max salary'\n",
    ")\n",
    "\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.title('Średnie dzienne wynagrodzenia', pad=20, fontsize=14)\n",
    "plt.xlabel('Data', labelpad=15)\n",
    "plt.ylabel('Wynagrodzenie (PLN)', labelpad=15)\n",
    "plt.grid(True, alpha=0.5)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "grouped = df.groupby(['scraped_at', 'experience'])['min_salary'].mean().reset_index()\n",
    "\n",
    "plt.figure(figsize=(14, 7))\n",
    "for seniority in grouped['experience'].unique():\n",
    "    subset = grouped[grouped['experience'] == seniority]\n",
    "    plt.plot(subset['scraped_at'], \n",
    "             subset['min_salary'], \n",
    "             marker='o', \n",
    "             label=seniority)\n",
    "\n",
    "plt.title('Średnie wynagrodzenia z podziałem na seniority')\n",
    "plt.legend(title='Poziom doświadczenia')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7034f0e0-31da-485b-b8ba-cc60490da00e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4570cd44-da9c-441d-9834-64c8c57beea8",
   "metadata": {},
   "source": [
    "### Predict salaries"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27d1b3c6-cacb-4190-85f8-c99a0356daf9",
   "metadata": {},
   "source": [
    "#### Without scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afad76cc-3f09-43a7-ba04-279318cab90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d4438ff-d1d9-4690-9400-17f067e7134c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.iloc[:, :12].head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f165b677-878d-4665-b731-7cb3ca414b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary.columns[:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fb73849-7114-4e3b-8bab-538608225e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['location', 'type_of_work', 'experience', 'employment_type', 'operating_mode']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deb5af2e-b5e6-4642-a37b-afc58f29d33a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary[features].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43802f66-d986-48cb-983b-e4851591173d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = all_data_with_salary[features]\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e28c647e-ace7-4df5-bee4-85becc0a25e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_with_salary[\"max_salary\"].head()\n",
    "print(type(all_data_with_salary[\"max_salary\"].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4011235-4adb-462d-be21-dfeaf43be08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = all_data_with_salary[\"max_salary\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62664cc4-d8fd-4619-853c-f22c470a959b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "origin_columns = all_data_with_salary[features]\n",
    "encoder = OneHotEncoder(sparse_output=False)\n",
    "X_encoded = encoder.fit_transform(origin_columns)\n",
    "# X_encoded[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c1c69b-8957-4582-bbc8-5e71440069bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8f5f13-5fb5-4732-bda4-879ef383fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e375a8e8-5eb9-4b39-a391-8b196b2c9880",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edeca302-fa22-4a12-885a-c953f83385e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from math import sqrt\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940cacf0-d7e0-41fd-8a2a-3bbebfa86112",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features = encoder.inverse_transform(X_encoded)\n",
    "original_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79dc04c-c527-4e57-9253-2ff7035f274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "original_features[:, 2][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96315db1-df42-4dd7-a682-3e5687d674ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(y_test)), y_test)\n",
    "plt.scatter(range(len(y_pred)), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3504e62a-bd75-4d1c-ad52-42ca78566c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_pred - y_test\n",
    "plt.scatter(range(len(errors)), errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2a53c1-cc3c-4e2d-a5f2-5a02c31693ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699387bc-04de-443f-80ea-b29a65d5241a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4e477de5-cf88-4084-a652-c6877f03164a",
   "metadata": {},
   "source": [
    "#### With PCA = 3 (for testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2603ef67-6684-4c6e-91ea-4939b52fe976",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af3b4fa-a0ed-4b6a-a54b-60048c8ed04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['location', 'type_of_work', 'experience', 'employment_type', 'operating_mode']\n",
    "X = all_data_with_salary[features]\n",
    "y = all_data_with_salary[\"max_salary\"]\n",
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_encoded = one_hot_encoder.fit_transform(X)\n",
    "print(X_encoded.shape)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y, test_size=0.2, random_state=42)\n",
    "\n",
    "pca = PCA(n_components=3)\n",
    "X_train_pca = pca.fit_transform(X_train)\n",
    "X_test_pca = pca.transform(X_test)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train_pca, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test_pca)\n",
    "print(y_test.iloc[:10].values.tolist())\n",
    "y_pred[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c908fa6-2962-4231-bdd9-4f29d07a618e",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = y_pred - y_test\n",
    "plt.hist(errors, bins=15, edgecolor=\"black\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cd8ffd-0f01-4165-bae3-4a0aedea5de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(y_test)), y_test)\n",
    "plt.scatter(range(len(y_pred)), y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489e1e59-14bb-404d-9ea9-d2445a0c43c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5db91a91-a2cb-4310-91f6-e190d1291aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "341ac39a-3b7b-48e0-9b95-5cb346ad8628",
   "metadata": {},
   "source": [
    "#### With Pipelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d279f34f-ff05-4f89-9a93-906fb24f7fba",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf4e3f7-a8e5-44a3-8deb-2b3581e5f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb694b3-e0ae-46e3-a334-def99c9764a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "])\n",
    "\n",
    "X_preprocessed = pipeline.fit_transform(X)\n",
    "X_preprocessed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90dc398d-02b6-4844-a03a-dabca018f114",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_preprocessed, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98bf8e83-065c-44ea-bae8-68e396141952",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86e326b6-e07d-4eee-8d5c-d1cbbc426796",
   "metadata": {},
   "source": [
    "#### Pipeline with PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e0f62-16ca-4beb-a126-77fa2189e451",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"pca\", PCA(n_components=3)),\n",
    "    (\"regressor\", LinearRegression()),\n",
    "])\n",
    "\n",
    "pipeline.fit(X_train, y_train)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e42625-0452-4350-a55d-7363059490b5",
   "metadata": {},
   "source": [
    "#### Pipeline with cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0cd705c-7023-4eca-9659-300a94d7aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa3cbc86-cbf5-456b-9d1a-6be1962ad418",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"regressor\", LinearRegression()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__fit_intercept\": [False, True],\n",
    "    \"pca__n_components\": list(np.arange(1,5))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(-grid_search.best_score_)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db5ed6-99ee-4482-8d9f-c4d0b11ae488",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7a1dcce-e60b-47bc-837e-16eb88b1ad7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"regressor\", Ridge()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__fit_intercept\": [False, True],\n",
    "    \"pca__n_components\": list(np.arange(1,5))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(-grid_search.best_score_)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ab3cb2-51a2-422e-9e39-b187bb05921d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"pca\", PCA()),\n",
    "    (\"regressor\", Lasso()),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__fit_intercept\": [False, True],\n",
    "    \"pca__n_components\": list(np.arange(1,5))\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_)\n",
    "print(-grid_search.best_score_)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc779d66-1727-4cf0-b47e-da6f97f50077",
   "metadata": {},
   "source": [
    "#### Train model RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a533ca9a-856f-4df1-a476-1248be5c0afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59da2cf-ad11-418a-84b1-2c865c4ff081",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"regressor\", RandomForestRegressor(random_state=42)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__n_estimators\": np.arange(30, 150, 20),\n",
    "    \"regressor__min_samples_leaf\": np.arange(1, 5, 2),\n",
    "    \"regressor__n_jobs\": [-1],\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "print(f\"Best params {grid_search.best_params_}\")\n",
    "print(f\"Best estimator {grid_search.best_estimator_}\")\n",
    "print(f\"Best score {-grid_search.best_score_}\")\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "146e7100-62e4-4f71-9dd3-d48c3f3b5d30",
   "metadata": {},
   "source": [
    "#### TRY WITH XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6859978-336b-4463-a67e-3628f6a85656",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82efa37d-d199-45b2-a4f3-1e4200db41f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"onehotencoder\", OneHotEncoder(), features)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    # (\"regressor\", XGBRegressor(learning_rate=1, objective='binary:logistic')), <== wrong objective = used for classifier not regression!\n",
    "    (\"regressor\", XGBRegressor(objective='reg:squarederror', learning_rate=0.1)),\n",
    "])\n",
    "\n",
    "param_grid = {\n",
    "    \"regressor__n_estimators\": np.arange(40, 120, 20),\n",
    "    \"regressor__max_depth\": np.arange(4, 6, 1),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, cv=5, scoring='neg_root_mean_squared_error')\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "y_pred = grid_search.predict(X_test)\n",
    "print(y_pred)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = sqrt(mse)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f'Błąd średniokwadratowy: {mse:.2f}')\n",
    "print(f'Pierwiastek z błędu średniokwadratowego: {rmse:.2f}')\n",
    "print(f'Błąd średni bezwzględny: {mae:.2f}')\n",
    "print(f'Współczynnik determinacji (R^2): {r2:.2f}')\n",
    "\n",
    "print(f\"Best params {grid_search.best_params_}\")\n",
    "print(f\"Best estimator {grid_search.best_estimator_}\")\n",
    "print(f\"Best RMSE {-grid_search.best_score_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c9770a-d1de-455e-bb8a-6f0010b0bf16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "006a6520-b30d-4f83-a813-b5cb70c5dc0e",
   "metadata": {},
   "source": [
    "#### Plot skills popularity by dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0aaa98-7c8b-48c3-a0a4-0fb017fe97c5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "pip install pandas matplotlib prophet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74dedda-fef4-43fe-941c-d063541dbf42",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from prophet import Prophet\n",
    "\n",
    "\n",
    "df = all_data_with_salary.groupby(\"scraped_at\")[top_skills_names].apply(lambda x: (x == 1).sum())\n",
    "df.index = pd.to_datetime(df.index)\n",
    "df = df.sort_index()\n",
    "skills = df.columns\n",
    "\n",
    "FORECAST_DAYS = 14\n",
    "forecast_results = {}\n",
    "\n",
    "for skill in skills:\n",
    "    skill_df = df[[skill]].reset_index()\n",
    "    skill_df.columns = ['ds', 'y']\n",
    "    \n",
    "    model = Prophet(daily_seasonality=True)\n",
    "    model.fit(skill_df)\n",
    "    future = model.make_future_dataframe(periods=FORECAST_DAYS)\n",
    "    forecast = model.predict(future)\n",
    "    forecast_results[skill] = forecast\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.plot(skill_df['ds'], skill_df['y'], label='Wartości historyczne')\n",
    "    # plt.plot(forecast['ds'], forecast['yhat'], label='Prognoza')\n",
    "    plt.fill_between(forecast['ds'], forecast['yhat_lower'], forecast['yhat_upper'], alpha=0.2, label='Przedział ufności')\n",
    "    plt.title(f\"Popularność skilla: {skill}\")\n",
    "    plt.xlabel('Data')\n",
    "    plt.ylabel('Liczba wystąpień')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd4367-6349-4d81-b0e3-4125e6bff3e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "42ee9412-b606-4e84-917b-3641a7359dc6",
   "metadata": {},
   "source": [
    "## Inne modele"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5bde49-a316-4ea7-9d35-5f4d7a829981",
   "metadata": {},
   "source": [
    "### Przewidywanie wynagrodzenia na podstawie posiadanych umiejętności w CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134928d4-ec90-415d-a02a-16fa8b5dc3ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbfaf65f-cd1f-4103-9e10-aca34ebc7c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d19c1ac-cf1c-415c-81c0-89cae3788a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "results = []\n",
    "# df = pd.read_csv('job_offers.csv')\n",
    "df = pd.read_csv('../Data analysis/wszystkie_dane_tylko_z_salary.csv')\n",
    "# ../Data analysis/wszystkie_dane_tylko_z_salary\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or salary == \"Missing salary\":\n",
    "        return np.nan\n",
    "    salary = salary.replace(\"PLN/month\", \"\").replace(\"PLN/h\", \"\").replace(\"PLN/year\", \"\").replace(\" \", \"\").split(\"-\")\n",
    "    if len(salary) == 1:\n",
    "        return int(salary[0])\n",
    "    return (int(salary[0]) + int(salary[1])) / 2\n",
    "\n",
    "df['min_salary'] = df['salary'].apply(parse_salary)\n",
    "print(len(df['min_salary']))\n",
    "df = df.dropna(subset=['min_salary']).reset_index(drop=True)\n",
    "print(len(df['min_salary']))\n",
    "cat_cols = ['type_of_work', 'operating_mode', 'employment_type', 'experience', 'location']\n",
    "base_cols = ['offer_id', 'title', 'company', 'location', 'salary', 'link', 'scraped_at', 'min_salary'] + cat_cols\n",
    "skill_cols = [col for col in df.columns if col not in base_cols]\n",
    "\n",
    "X = df[cat_cols + skill_cols]\n",
    "y = df['min_salary']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough'  \n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(n_estimators=100, random_state=42))\n",
    "])\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "results.append(mae)\n",
    "print(\"Mean Absolute Error:\", mae)\n",
    "print(y_pred[:5])\n",
    "print(y_test[:5])\n",
    "\n",
    "print(len(y_pred))\n",
    "print(len(y_test))\n",
    "\n",
    "# plt.hist(y_pred - y_test, bins=20)\n",
    "plt.hist(y_pred - y_test, bins=40)\n",
    "\n",
    "def get_user_input(skill_columns):\n",
    "    print(\"\\nWprowadź dane dotyczące oferty pracy:\")\n",
    "    data = {}\n",
    "    # data['type_of_work'] = \"Full-time\"\n",
    "    # data['operating_mode'] = \"Remote\"\n",
    "    # data['employment_type'] = \"B2B\"\n",
    "    # data['experience'] = \"Senior\"\n",
    "    # data['location'] = \"Warszawa\"\n",
    "\n",
    "    data['type_of_work'] = \"Full-time\"\n",
    "    data['operating_mode'] = \"Remote\"\n",
    "    data['employment_type'] = \"B2B\"\n",
    "    data['experience'] = \"Mid\"\n",
    "    data['location'] = \"Gliwice\"\n",
    "\n",
    "    print(\"\\nWprowadź wymagane umiejętności, oddzielone przecinkami (np.: .NET C#, Python, ML):\")\n",
    "    user_skills_input = input()\n",
    "    user_skills = [s.strip().lower() for s in user_skills_input.split(\",\") if s.strip()]\n",
    "\n",
    "    print(\"user_skills_input\", user_skills_input)\n",
    "    \n",
    "    skills = {}\n",
    "    for col in skill_columns:\n",
    "        skills[col] = 1 if col.lower() in user_skills else 0\n",
    "\n",
    "    # print(\"skills\", skills)\n",
    "    \n",
    "    data.update(skills)\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "user_input = get_user_input(skill_cols)\n",
    "predicted_salary = model.predict(user_input)\n",
    "print(\"\\nExpected salary (default parameters):\", predicted_salary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97d7db05-355a-41fd-bee7-3f404e2315f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastapi, TensorFlow, Python, Machine Learning, Flask, Django, Docker, Cloud, AWS, API\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a27cb6f-9945-422e-97cf-717a8e6c74bc",
   "metadata": {},
   "source": [
    "#### Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc235b-02c8-4f7b-8b23-74bb6508d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "results = []\n",
    "df = pd.read_csv('../Data analysis/wszystkie_dane_tylko_z_salary.csv')\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or salary == \"Missing salary\":\n",
    "        return np.nan\n",
    "    salary = salary.replace(\"PLN/month\", \"\").replace(\"PLN/h\", \"\").replace(\"PLN/year\", \"\").replace(\" \", \"\").split(\"-\")\n",
    "    if len(salary) == 1:\n",
    "        return int(salary[0])\n",
    "    return (int(salary[0]) + int(salary[1])) / 2\n",
    "\n",
    "df['min_salary'] = df['salary'].apply(parse_salary)\n",
    "df = df.dropna(subset=['min_salary']).reset_index(drop=True)\n",
    "cat_cols = ['type_of_work', 'operating_mode', 'employment_type', 'experience', 'location']\n",
    "base_cols = ['offer_id', 'title', 'company', 'location', 'salary', 'link', 'scraped_at', 'min_salary'] + cat_cols\n",
    "skill_cols = [col for col in df.columns if col not in base_cols]\n",
    "\n",
    "X = df[cat_cols + skill_cols]\n",
    "y = df['min_salary']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', RandomForestRegressor(random_state=42))\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    \"regressor__n_estimators\": np.arange(25, 100, 25),\n",
    "    \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid=grid_params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_.predict(X_test))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "results.append(mae)\n",
    "\n",
    "def get_user_input(skill_columns):\n",
    "\n",
    "    print(\"\\nWprowadź dane dotyczące oferty pracy:\")\n",
    "    data = {}\n",
    "    # data['type_of_work'] = \"Full-time\"\n",
    "    # data['operating_mode'] = \"Remote\"\n",
    "    # data['employment_type'] = \"B2B\"\n",
    "    # data['experience'] = \"Senior\"\n",
    "    # data['location'] = \"Warszawa\"\n",
    "\n",
    "    data['type_of_work'] = \"Full-time\"\n",
    "    data['operating_mode'] = \"Remote\"\n",
    "    data['employment_type'] = \"B2B\"\n",
    "    data['experience'] = \"Mid\"\n",
    "    data['location'] = \"Gliwice\"\n",
    "\n",
    "    # print(\"\\nWprowadź wymagane umiejętności, oddzielone przecinkami (np.: .NET C#, Python, ML):\")\n",
    "    # user_skills_input = input()\n",
    "    user_skills_input = \" AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript\"\n",
    "    user_skills = [s.strip().lower() for s in user_skills_input.split(\",\") if s.strip()]\n",
    "    skills = {}\n",
    "    for col in skill_columns:\n",
    "        skills[col] = 1 if col.lower() in user_skills else 0\n",
    "\n",
    "    data.update(skills)\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "user_input = get_user_input(skill_cols)\n",
    "predicted_salary = model.predict(user_input)\n",
    "print(\"\\nExpected salary (default parameters):\", predicted_salary[0])\n",
    "\n",
    "grid_search_predicted_salary = grid_search.best_estimator_.predict(user_input)\n",
    "print(\"\\ngrid_search_predicted_salary (PLN/miesiąc):\", grid_search_predicted_salary[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9f3520-9bd2-4bde-b1c0-678f46fb4c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastapi, TensorFlow, Python, Machine Learning, Flask, Django, Docker, Cloud, AWS, API\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4c05cc8-2167-4b94-b632-4b7d48c15fff",
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search_predicted_salary = grid_search.best_estimator_.predict(user_input)\n",
    "print(\"\\ngrid_search_predicted_salary (PLN/miesiąc):\", grid_search_predicted_salary[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19ba082b-fce5-4ed1-8bc8-bab6b40144a4",
   "metadata": {},
   "source": [
    "#### LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10a68177-6b35-4b9d-84a3-e93b7d1d6bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30af4e0d-a5af-4e5d-b7ab-d048f862e75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "results = []\n",
    "df = pd.read_csv('../Data analysis/wszystkie_dane_tylko_z_salary.csv')\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or salary == \"Missing salary\":\n",
    "        return np.nan\n",
    "    salary = salary.replace(\"PLN/month\", \"\").replace(\"PLN/h\", \"\").replace(\"PLN/year\", \"\").replace(\" \", \"\").split(\"-\")\n",
    "    if len(salary) == 1:\n",
    "        return int(salary[0])\n",
    "    return (int(salary[0]) + int(salary[1])) / 2\n",
    "\n",
    "df['min_salary'] = df['salary'].apply(parse_salary)\n",
    "df = df.dropna(subset=['min_salary']).reset_index(drop=True)\n",
    "cat_cols = ['type_of_work', 'operating_mode', 'employment_type', 'experience', 'location']\n",
    "base_cols = ['offer_id', 'title', 'company', 'location', 'salary', 'link', 'scraped_at', 'min_salary'] + cat_cols\n",
    "skill_cols = [col for col in df.columns if col not in base_cols]\n",
    "\n",
    "X = df[cat_cols + skill_cols]\n",
    "y = df['min_salary']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', LinearRegression())\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    \"regressor__fit_intercept\": [True, False],\n",
    "    # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid=grid_params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_.predict(X_test))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "results.append(mae)\n",
    "\n",
    "def get_user_input(skill_columns):\n",
    "    print(\"\\nWprowadź dane dotyczące oferty pracy:\")\n",
    "    data = {}\n",
    "    # data['type_of_work'] = \"Full-time\"\n",
    "    # data['operating_mode'] = \"Remote\"\n",
    "    # data['employment_type'] = \"B2B\"\n",
    "    # data['experience'] = \"Senior\"\n",
    "    # data['location'] = \"Warszawa\"\n",
    "\n",
    "    data['type_of_work'] = \"Full-time\"\n",
    "    data['operating_mode'] = \"Remote\"\n",
    "    data['employment_type'] = \"B2B\"\n",
    "    data['experience'] = \"Mid\"\n",
    "    data['location'] = \"Gliwice\"\n",
    "\n",
    "    user_skills_input = \" AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript\"\n",
    "    user_skills = [s.strip().lower() for s in user_skills_input.split(\",\") if s.strip()]\n",
    "\n",
    "    skills = {}\n",
    "    for col in skill_columns:\n",
    "        skills[col] = 1 if col.lower() in user_skills else 0\n",
    "\n",
    "    data.update(skills)\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "user_input = get_user_input(skill_cols)\n",
    "\n",
    "predicted_salary = model.predict(user_input)\n",
    "print(\"\\nExpected salary (default parameters):\", predicted_salary[0])\n",
    "\n",
    "grid_search_predicted_salary = grid_search.best_estimator_.predict(user_input)\n",
    "print(\"\\ngrid_search_predicted_salary (PLN/miesiąc):\", grid_search_predicted_salary[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e12847-302e-41f1-8448-7f0244da1a89",
   "metadata": {},
   "source": [
    "#### KNN Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c339cdb-376c-46b5-bda6-5417ed862b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "results = []\n",
    "df = pd.read_csv('../Data analysis/wszystkie_dane_tylko_z_salary.csv')\n",
    "\n",
    "def parse_salary(salary):\n",
    "    if pd.isna(salary) or salary == \"Missing salary\":\n",
    "        return np.nan\n",
    "    salary = salary.replace(\"PLN/month\", \"\").replace(\"PLN/h\", \"\").replace(\"PLN/year\", \"\").replace(\" \", \"\").split(\"-\")\n",
    "    if len(salary) == 1:\n",
    "        return int(salary[0])\n",
    "    return (int(salary[0]) + int(salary[1])) / 2\n",
    "\n",
    "df['min_salary'] = df['salary'].apply(parse_salary)\n",
    "df = df.dropna(subset=['min_salary']).reset_index(drop=True)\n",
    "cat_cols = ['type_of_work', 'operating_mode', 'employment_type', 'experience', 'location']\n",
    "base_cols = ['offer_id', 'title', 'company', 'location', 'salary', 'link', 'scraped_at', 'min_salary'] + cat_cols\n",
    "skill_cols = [col for col in df.columns if col not in base_cols]\n",
    "\n",
    "X = df[cat_cols + skill_cols]\n",
    "y = df['min_salary']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore'), cat_cols)\n",
    "    ],\n",
    "    remainder='passthrough' \n",
    ")\n",
    "\n",
    "model = Pipeline(steps=[\n",
    "    ('preprocessor', preprocessor),\n",
    "    ('regressor', KNeighborsRegressor())\n",
    "])\n",
    "\n",
    "grid_params = {\n",
    "    \"regressor__n_neighbors\": np.arange(5, 20, 5),\n",
    "    \"regressor__algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "    # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "    # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "grid_search = GridSearchCV(model, param_grid=grid_params, cv=5, scoring='neg_root_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_estimator_.predict(X_test))\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "results.append(mae)\n",
    "# print(\"Mean Absolute Error (MAE):\", mean_absolute_error(y_test, y_pred))\n",
    "# print(\"Mean Squared Error (MSE):\", mean_squared_error(y_test, y_pred))\n",
    "# print(\"Root Mean Squared Error (RMSE):\", np.sqrt(mean_squared_error(y_test, y_pred)))\n",
    "# print(\"R2 Score:\", r2_score(y_test, y_pred))\n",
    "# plt.hist(y_pred - y_test, bins=40)\n",
    "\n",
    "def get_user_input(skill_columns):\n",
    "    print(\"\\nWprowadź dane dotyczące oferty pracy:\")\n",
    "    data = {}\n",
    "    data['type_of_work'] = \"Full-time\"\n",
    "    data['operating_mode'] = \"Remote\"\n",
    "    data['employment_type'] = \"B2B\"\n",
    "    data['experience'] = \"Mid\"\n",
    "    data['location'] = \"Gliwice\"\n",
    "\n",
    "    user_skills_input = \" AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript\"\n",
    "    user_skills = [s.strip().lower() for s in user_skills_input.split(\",\") if s.strip()]\n",
    "\n",
    "    skills = {}\n",
    "    for col in skill_columns:\n",
    "        skills[col] = 1 if col.lower() in user_skills else 0\n",
    "\n",
    "    data.update(skills)\n",
    "    return pd.DataFrame([data])\n",
    "\n",
    "user_input = get_user_input(skill_cols)\n",
    "\n",
    "predicted_salary = model.predict(user_input)\n",
    "print(\"\\nExpected salary (default parameters):\", predicted_salary[0])\n",
    "\n",
    "grid_search_predicted_salary = grid_search.best_estimator_.predict(user_input)\n",
    "print(\"\\ngrid_search_predicted_salary (PLN/miesiąc):\", grid_search_predicted_salary[0])\n",
    "\n",
    "\n",
    "# Mean Absolute Error (MAE): 5274.05638888889\n",
    "# Mean Squared Error (MSE): 51627118.65147361\n",
    "# Root Mean Squared Error (RMSE): 7185.201364713003\n",
    "# R2 Score: 0.20971367245488715\n",
    "# Expected salary (default parameters): 14769.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb725c2-80bf-4dcd-b6ef-d82d9e502d97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3af4d67a-e694-4a87-ba2c-e384e23f241c",
   "metadata": {},
   "source": [
    "### One Ring to rule them all, One Ring to find them, One Ring to bring them all and in the darkness bind them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "503c559c-2ea7-4b7b-a9d6-6e0b1e14f7f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "all_data_with_salary = pd.read_csv(\"../Data analysis/wszystkie_dane_tylko_z_salary.csv\")\n",
    "all_data_with_salary.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91455bea-2e61-4386-a6e9-b92652076dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_data_with_salary.shape)\n",
    "all_data_with_salary.dropna()\n",
    "print(all_data_with_salary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813eafd6-2fbd-4e7b-8855-a8c1398d41e6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(all_data_with_salary.columns[:12])\n",
    "\n",
    "operation_cols = ['location', 'type_of_work', 'experience', 'employment_type', 'operating_mode']\n",
    "skill_cols = all_data_with_salary.columns[12:].tolist() \n",
    "\n",
    "X = all_data_with_salary[operation_cols + skill_cols]\n",
    "y = all_data_with_salary.min_salary\n",
    "y.head()\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        (\"cat\", OneHotEncoder(), operation_cols)\n",
    "    ],\n",
    "    remainder=\"passthrough\"\n",
    ")\n",
    "\n",
    "MODEL_MAP = {\n",
    "    \"RandomForestRegressor\": RandomForestRegressor,\n",
    "    \"LinearRegression\": LinearRegression,\n",
    "    \"KNeighborsRegressor\": KNeighborsRegressor\n",
    "}\n",
    "\n",
    "models = [\n",
    "    {\n",
    "        \"model\": \"RandomForestRegressor\",\n",
    "        \"params\": {\n",
    "            \"regressor__n_estimators\": np.arange(50, 100, 50),\n",
    "            \"regressor__criterion\": [\"squared_error\"]\n",
    "            # \"regressor__criterion\": [\"squared_error\", \"absolute_error\", \"friedman_mse\", \"poisson\"]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": \"LinearRegression\",\n",
    "        \"params\": {\n",
    "            \"regressor__fit_intercept\": [True, False],\n",
    "        }\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"model\": \"KNeighborsRegressor\",\n",
    "        \"params\": {\n",
    "            \"regressor__n_neighbors\": np.arange(5, 10, 5),\n",
    "            \"regressor__algorithm\": [\"auto\", \"ball_tree\"]\n",
    "            # \"regressor__algorithm\": [\"auto\", \"ball_tree\", \"kd_tree\", \"brute\"]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "for model_config in models:  \n",
    "    print(f\"\\n{'='*30}\\nTesting {model_config['model']}\\n{'='*30}\")\n",
    "\n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"preprocessor\", preprocessor),\n",
    "            (\"regressor\", MODEL_MAP[model_config[\"model\"]]()) \n",
    "        ]\n",
    "    )\n",
    "\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)\n",
    "    grid_search_cv = GridSearchCV(estimator=pipeline, param_grid=model_config[\"params\"], cv=5, scoring='neg_root_mean_squared_error')\n",
    "    grid_search_cv.fit(X_train, y_train)\n",
    "    print(model_config[\"model\"])\n",
    "    print(grid_search_cv.best_estimator_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aec8bf4-eaa4-4a43-bf1c-c1102c35e4cc",
   "metadata": {},
   "source": [
    "### Jobs categories classification: Data Scientist, Machine Learning Engineer, Software Engineer / Developer, Manager / Director / Lead, Other"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c68fe24-4020-45be-b939-a0f465a85827",
   "metadata": {},
   "source": [
    "#### ADD!!! Add classified titles and drop duplicates (drop scratched_at and offer_id) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c00a31-aa6d-4ccf-9034-8ad5fc8706a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df = pd.read_csv(\"../Data analysis/wszystkie_dane_zlaczone_z_i_bez_salary.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cccac1-d4f1-4d28-be33-1afdfadb399b",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b8a2e7-2c46-47d1-b8cb-dac6a97acd11",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_classified_title_df = pd.read_csv(\"../Data analysis/skills_classified_title_only.csv\")\n",
    "skills_classified_title_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10f383-c1e7-4b79-b50e-f6e01189fe2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4399e7-55ce-4f42-b7d2-23e43e3a7d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "skills_classified_title_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8614709a-6dde-49fc-b6bd-ece1f610ca4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e5661fa-39f0-436c-b5e3-24e3351531b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.insert(0, \"skills_classified_title\", skills_classified_title_df.iloc[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59347d53-495e-4098-97b0-7c9095af2b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(all_data_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933fe25-e33a-4ce5-b5c8-c76e15e419f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b40646f-82c6-4fe3-b17d-378f1f6943a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6924cbc2-16b4-47f0-bdca-4eb4319c693a",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data_df.drop(columns=[\"scraped_at\", \"offer_id\"], inplace=True)\n",
    "all_data_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a64b626b-0d55-486e-af52-6958defce28a",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_all_data_df = all_data_df.copy()\n",
    "copied_all_data_df[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f936455-4a42-4b95-b0d2-e11a3bd8ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_all_data_df.drop_duplicates(inplace=True)\n",
    "print(copied_all_data_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edecc9b-2b70-477c-ad2e-c1d64cb81d5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94343f7e-54d5-4af0-869a-b7779499d84e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d72094-8262-440e-ac57-3fbeb35959e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a4e789a-0c17-45b3-91ca-745450637867",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e86cca51-97dc-447b-802d-ec725e085707",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93b20acd-40aa-4064-9054-1b1b7ac0b2af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6e678-a4bf-44f3-86c5-1de4b986cd81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "data_with_jobs_classified = copied_all_data_df.copy() \n",
    "# data_with_jobs_classified.head(3)\n",
    "print(len(data_with_jobs_classified))\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "print(len(data_with_jobs_classified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bbe7aa-1f8c-470a-b775-760aa42220ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[\"skills_classified_title\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a04b3ec-c7a8-48cd-aef6-ec263390cc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "skill_cols.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "488e590c-ebd3-46ef-97e5-652f73fd050a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2577839a-5ecc-4b67-a39b-a8471b09d846",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(skill_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b094780-7375-4a5c-adaa-e1563fee83e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = skill_cols\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff823599-1cf2-4d60-8336-319d784ca81e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12953341-9f5f-47e2-9806-7fc14931b0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd5c590-3614-4a5a-84cc-91041ff4bef9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(set(y_train_encoded))\n",
    "print(label_encoder.classes_)\n",
    "for i, category in enumerate(label_encoder.classes_):\n",
    "    print(i, category)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518bac6a-0a7c-42c2-803c-bd0519b161d0",
   "metadata": {},
   "source": [
    "#### Version with pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b4be029-f3ff-4291-b1ea-40058a37b8db",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "pipeline.fit(X_train, y_train_encoded)\n",
    "y_pred = pipeline.predict(X_test)\n",
    "print(f\"{y_pred[6:20]}\\n{y_test_encoded[6:20]}\")\n",
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test_encoded, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50d78cb2-203b-42ed-bff0-c45485575f38",
   "metadata": {},
   "source": [
    "#### Version with GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1840a7be-c2e1-4c17-b4d6-aecabb17e197",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique, counts = np.unique(y_train_encoded, return_counts=True)\n",
    "print(unique, counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0431569-17bb-44a6-8e26-bcdf7389bd34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38ef68c-16b6-4a16-ba44-c25134071d9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__penalty\": ['l2', \"elasticnet\"],\n",
    "    # \"penalty\": ['l1', 'l2', 'elasticnet', None],\n",
    "    \"model__C\": [0.001, 0.01, 0.1, 1, 10],\n",
    "    \"model__max_iter\": np.arange(50, 300, 100),\n",
    "    \"model__n_jobs\": [-1],\n",
    "    # \"model__solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "    \"model__solver\": ['saga'],\n",
    "    \"model__l1_ratio\": np.arange(0, 1, 0.1),\n",
    "    # \"model__max_iter\": np.arange(100, 1000, 300)\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.classes_)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "\n",
    "accuracy_score(y_test_encoded, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730b8df1-6e99-426b-8928-14f0de00e477",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c16ed772-5b8f-4826-b269-42ca3bc03f34",
   "metadata": {},
   "source": [
    "#### Combined model code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c06ebd-a294-476f-ad01-6becdb8bc59c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "data_with_jobs_classified.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa01e19-a601-49b3-af01-5eed97235e7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd7eea35-60bb-400e-a363-3308fb93b61e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46989159-e7e7-49c9-8cdc-a58f92bba203",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "381f2cd9-622d-41d0-979c-75e650f7e61a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dec2db3-fdc5-4480-8979-c69cb7054f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = skill_cols\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "print(X.shape, y.shape)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.2, random_state=42)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.fit_transform(y_test)\n",
    "\n",
    "unique, counts = np.unique(y_train_encoded, return_counts=True)\n",
    "print(unique, counts)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__penalty\": [\"elasticnet\"],\n",
    "    # \"penalty\": ['l1', 'l2', 'elasticnet', None],\n",
    "    \"model__C\": [0.1, 1, 0.3],\n",
    "    \"model__max_iter\": np.arange(150, 300, 150),\n",
    "    \"model__n_jobs\": [-1],\n",
    "    # \"model__solver\": ['lbfgs', 'liblinear', 'newton-cg', 'newton-cholesky', 'sag', 'saga']\n",
    "    \"model__solver\": ['saga'],\n",
    "    \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "print(grid_search.best_estimator_)\n",
    "print(grid_search.best_params_)\n",
    "print(grid_search.best_score_)\n",
    "print(grid_search.classes_)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "accuracy_score(y_test_encoded, y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11c452a-8dc3-45a5-b1d6-64be3bb6b8d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastapi, TensorFlow, Python, Machine Learning, Flask, Django, Docker, Cloud, AWS, API\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee0917c-f13c-47a7-a813-bdb16b124c43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# skills_classified_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c03d54-86c7-4898-b509-476d4f76ca1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified.head(3)\n",
    "print(len(data_with_jobs_classified))\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "print(len(data_with_jobs_classified))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7999d7ef-c36f-4099-a9b6-72148f69ad20",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3406954f-dbad-4bb2-8c25-d108e688e1a9",
   "metadata": {},
   "source": [
    "#### Model that takes input from user (testing version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b6bd7b6-b569-4cdb-953c-a304abfb2161",
   "metadata": {},
   "outputs": [],
   "source": [
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "# print(skill_cols)\n",
    "# type(skill_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14776260-1fea-449c-99c0-332b57194169",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastapi, TensorFlow, Python, Machine Learning, Flask, Django, Docker, Cloud, AWS, API\n",
    "user_skills = [\"flask\", \"django\", \"aws\", \"cloud\", \"api\"]\n",
    "base_skills = [\"flask\", \"aws\", \"cloud\"]\n",
    "\n",
    "dictionary = {}\n",
    "\n",
    "for col in user_skills:\n",
    "    dictionary[col] = 1 if col in base_skills else 0\n",
    "\n",
    "print(\"dictionary\", dictionary)\n",
    "print(user_skills)\n",
    "\n",
    "skillls = [skill.capitalize() for skill in user_skills if skill not in base_skills]\n",
    "print(skillls)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad8b70a7-23c5-4139-b73f-b4ad4f86a502",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aae87c1b-f6ec-4a7e-9efd-20be33adaf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "377b712f-f90e-49a2-864d-1b8a2f328819",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"AI Product Manager\"].head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51f1910-eb3e-4e0b-92b2-fc9aecb82ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"AI Product Manager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "498d58cf-0568-47a6-87eb-753d33f788d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e2c1d57-ef74-476a-af8c-b9113fec92f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba1dc92-86a2-4334-bb19-bf8ce7754c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40aed092-bf82-4620-86c6-254a8058faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[\"skills_classified_title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc409eb-5929-4983-9c1b-956b917555c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified[\"skills_classified_title\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f02e8b06-4172-44df-b5b4-290a48f33219",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "counts\n",
    "# values_to_keep = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b75975c-143c-4a36-9a37-3fe889bbd5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TESTING SECTION\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d9d510-9d95-4987-a944-bc6f234d9463",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_keep = counts[counts > 1]\n",
    "values_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bc757f-9c65-4841-9077-9ba12e7915f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "values_to_keep = counts[counts > 1].index\n",
    "values_to_keep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc2230b8-8d64-4ab3-a666-7be87e7cf3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "copied_all_data_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618d480-f0d8-42b8-879b-75adb9238faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "print(len(data_with_jobs_classified))\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "# print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "print(values_to_keep)\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "data_with_jobs_classified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d56ee3a-2001-44ba-acb1-d843847dceb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# print(len(data_with_jobs_classified))\n",
    "# counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "# # print(counts)\n",
    "# values_to_keep = counts[counts > 1].index\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "# # print(values_to_keep)\n",
    "# # data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]\n",
    "\n",
    "# TESTING SECTION\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]\n",
    "\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"AI Product Manager\"]\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"ML Operations Engineer\"]\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Data Architect\"]\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "\n",
    "\n",
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "if not isinstance(skill_cols, list):\n",
    "    print(f\"skill_cols nie jest listą nazw kolumn! Zmiana z {type(skill_cols)} na listę!\")\n",
    "    skill_cols = list(skill_cols)  # albo ręcznie wpisz nazwy\n",
    "\n",
    "print(\"len(skill_cols)\", len(skill_cols))\n",
    "print(\"len(data_with_jobs_classified)\", len(data_with_jobs_classified))\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "\n",
    "def select_skills(data, available_skills):\n",
    "    selected_names = input(\"Podaj nazwy skilli, oddzielone przecinkami (np. Python,SQL,Excel): \")\n",
    "    selected_skills = [name.strip() for name in selected_names.split(\",\")]\n",
    "    not_in_db_skills = [skill for skill in selected_skills if skill not in available_skills]\n",
    "    print(\"not_in_db_skills\", not_in_db_skills)\n",
    "        \n",
    "    print(f\"Wybrane skille: {selected_skills}\")\n",
    "    return selected_skills\n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__penalty\": [\"elasticnet\"],\n",
    "    \"model__C\": [0.1, 1, 0.3],\n",
    "    \"model__max_iter\": np.arange(150, 300, 150),\n",
    "    \"model__n_jobs\": [-1],\n",
    "    \"model__solver\": ['saga'],\n",
    "    \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "\n",
    "print(\"Model gotowy!\")\n",
    "\n",
    "# Pobranie skilli do predykcji\n",
    "selected_skills = select_skills(data_with_jobs_classified, skill_cols)\n",
    "\n",
    "if selected_skills:\n",
    "    # Utworzenie wektora wejściowego\n",
    "    input_vector = []\n",
    "    for skill in skill_cols:\n",
    "        if skill in selected_skills:\n",
    "            input_vector.append(1)  # Skill obecny\n",
    "        else:\n",
    "            input_vector.append(0)  # Skill nieobecny\n",
    "\n",
    "    print(\"input_vector\", input_vector)\n",
    "    print(\"len(input_vector)\", len(input_vector))\n",
    "    \n",
    "    import numpy as np\n",
    "    # input_array = np.array(input_vector).reshape(1, -1)\n",
    "    input_array = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "    print(\"input_array\", input_array)\n",
    "\n",
    "    # Predykcja\n",
    "    predicted_label_encoded = grid_search.best_estimator_.predict(input_array)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "    print(f\"➡️ Przewidywana kategoria encoded: {predicted_label_encoded}\")\n",
    "    print(f\"➡️ Przewidywana kategoria: {predicted_label}\")\n",
    "else:\n",
    "    print(\"Nie podano poprawnych skilli. Koniec.\")\n",
    "\n",
    "# Flask, Django, Docker, Cloud, AWS, API\n",
    "# input_vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript     \n",
    "# input_vector [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b147be3-4314-42e5-998a-a472b840ace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fastapi, TensorFlow, Python, Machine Learning, Flask, Django, Docker, Cloud, AWS, API\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffba3cb-e8da-4594-a6b8-7cce2feb9692",
   "metadata": {},
   "source": [
    "#### Model that takes input from user (final version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60566bb9-3eb2-4e58-a0f9-baddcc6ca637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "\n",
    "# TESTING SECTION\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]\n",
    "\n",
    "\n",
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "\n",
    "if not isinstance(skill_cols, list):\n",
    "    print(f\"skill_cols is not a list of skill names! Zmiana z {type(skill_cols)} na listę!\")\n",
    "    skill_cols = list(skill_cols)  \n",
    "\n",
    "# X = data_with_jobs_classified[skill_cols]\n",
    "\n",
    "def select_skills(data, available_skills):\n",
    "    # selected_names = input(\"Please write skills, separated by commas (e.g.. Python,SQL,Excel): \")\n",
    "    selected_names = \"Flask, Django, Docker, Cloud, AWS, API\"\n",
    "    selected_skills = [name.strip() for name in selected_names.split(\",\")]\n",
    "    not_in_db_skills = [skill for skill in selected_skills if skill not in available_skills]\n",
    "    return selected_skills\n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", LogisticRegression())\n",
    "    ]\n",
    ")\n",
    "\n",
    "param_grid = {\n",
    "    \"model__penalty\": [\"elasticnet\"],\n",
    "    \"model__C\": [0.1, 1, 0.3],\n",
    "    \"model__max_iter\": np.arange(150, 300, 150),\n",
    "    \"model__n_jobs\": [-1],\n",
    "    \"model__solver\": ['saga'],\n",
    "    \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=param_grid, n_jobs=-1, cv=2)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "print(\"Accuracy score\", accuracy_score(y_test_encoded, y_pred))\n",
    "\n",
    "print(\"Model trained and ready to roll!\")\n",
    "\n",
    "selected_skills = select_skills(data_with_jobs_classified, skill_cols)\n",
    "\n",
    "# if selected_skills:\n",
    "#     input_vector = []\n",
    "#     for skill in skill_cols:\n",
    "#         if skill in selected_skills:\n",
    "#             input_vector.append(1)\n",
    "#         else:\n",
    "#             input_vector.append(0)\n",
    "\n",
    "#     # Tworzymy DataFrame z nazwami kolumn\n",
    "#     input_df = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "\n",
    "#     predicted_label_encoded = grid_search.best_estimator_.predict(input_df)[0]\n",
    "#     predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "#     print(f\"Predicted category encoded: {predicted_label_encoded}\")\n",
    "#     print(f\"Predicted category: {predicted_label}\")\n",
    "# else:\n",
    "#     print(\"You don't write any skill. End program.\")\n",
    "\n",
    "if selected_skills:\n",
    "    input_vector = []\n",
    "    for skill in skill_cols:\n",
    "        if skill in selected_skills:\n",
    "            input_vector.append(1) \n",
    "        else:\n",
    "            input_vector.append(0)\n",
    "    \n",
    "    print(\"input_vector\", input_vector)\n",
    "    # input_array = np.array(input_vector).reshape(1, -1)\n",
    "    input_array = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "    print(\"input_array\", input_array)\n",
    "    predicted_label_encoded = grid_search.best_estimator_.predict(input_array)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "    print(f\"Predicted category encoded: {predicted_label_encoded}\")\n",
    "    print(f\"Predicted category: {predicted_label}\")\n",
    "else:\n",
    "    print(\"You don't write any skill. End program.\")\n",
    "\n",
    "# Flask, Django, Docker, Cloud, AWS, API\n",
    "# input_vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript     \n",
    "# input_vector [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57ac301-93d6-49e2-8d4c-db01fe91d2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3e9d6d8-d5ff-493d-9302-67f5a13def4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "\n",
    "# TESTING SECTION\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "# data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] == \"AI Product Manager\"]\n",
    "\n",
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "\n",
    "if not isinstance(skill_cols, list):\n",
    "    print(f\"skill_cols is not a list of skill names! Zmiana z {type(skill_cols)} na listę!\")\n",
    "    skill_cols = list(skill_cols)  \n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "\n",
    "def select_skills(data, available_skills):\n",
    "    # Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "    # selected_names = input(\"Please write skills, separated by commas (e.g.. Python,SQL,Excel): \")\n",
    "    selected_names = \"Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\"\n",
    "    print(\"selected_names\", selected_names)\n",
    "    print(\"type(selected_names)\", type(selected_names))\n",
    "    selected_skills = [name.strip() for name in selected_names.split(\",\")]\n",
    "    not_in_db_skills = [skill for skill in selected_skills if skill not in available_skills]\n",
    "    return selected_skills\n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "\n",
    "MODELS_MAP = {\n",
    "    \"LogisticRegression\": LogisticRegression,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier,\n",
    "    \"XGBClassifier\": XGBClassifier,\n",
    "    \"XGBRFClassifier\": XGBRFClassifier,\n",
    "    \"LinearSVC\": LinearSVC,\n",
    "    # \"NuSVC\": NuSVC  <== VERIFY IN FUTURE!!!\n",
    "    \"SVC\": SVC\n",
    "}\n",
    "\n",
    "models = [\n",
    "   {\n",
    "        \"classifier\": MODELS_MAP[\"LogisticRegression\"],\n",
    "        \"params\": {\n",
    "            \"model__penalty\": [\"elasticnet\"],\n",
    "            \"model__C\": [0.1, 1, 0.3],\n",
    "            \"model__max_iter\": np.arange(150, 300, 150),\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__solver\": ['saga'],\n",
    "            \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"RandomForestClassifier\"],\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200, 100],\n",
    "            'model__max_depth': [10, 20, None],\n",
    "            'model__min_samples_split': [2, 3, 4, 5],\n",
    "            'model__min_samples_leaf': [1, 2, 4],\n",
    "            'model__max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"KNeighborsClassifier\"],\n",
    "        \"params\": {\n",
    "            'model__n_neighbors': [3, 5, 10, 15],\n",
    "            'model__weights': ['uniform', 'distance'],\n",
    "            'model__metric': ['minkowski', 'euclidean'],\n",
    "            'model__p': [1, 2],\n",
    "            'model__algorithm': ['auto', 'ball_tree']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"XGBClassifier\"],\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [3, 5],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            # 'model__reg_alpha': [0, 0.1, 1, 10],\n",
    "            # 'model__reg_lambda': [0, 0.1, 1, 10]\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [0, 0.1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"XGBRFClassifier\"],\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [200, 300],\n",
    "            'model__max_depth': [5, 7, 10],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"LinearSVC\"],\n",
    "        \"params\": {\n",
    "            'model__C': [0.01, 0.1, 1, 10],\n",
    "            'model__loss': ['hinge', 'squared_hinge'],\n",
    "            'model__penalty': ['l2'],\n",
    "            'model__dual': [True],\n",
    "            'model__max_iter': [1000, 5000]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": MODELS_MAP[\"SVC\"],\n",
    "        \"params\": {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'model__gamma': ['scale', 'auto', 0.1],\n",
    "            'model__degree': [2, 3],\n",
    "            'model__coef0': [0.0, 0.5]\n",
    "        }\n",
    "    },\n",
    "    # {\n",
    "    #     \"classifier\": MODELS_MAP[\"NuSVC\"],\n",
    "    #     \"params\": {\n",
    "    #         'model__nu': [0.1, 0.3, 0.5],\n",
    "    #         'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "    #         'model__gamma': ['scale', 'auto', 0.1],\n",
    "    #         'model__degree': [2, 3],\n",
    "    #         'model__coef0': [0.0, 0.5]\n",
    "    #     }\n",
    "    # },\n",
    "    \n",
    "]\n",
    "\n",
    "pipeline = Pipeline(\n",
    "    steps=[\n",
    "        (\"model\", models[0][\"classifier\"]())\n",
    "    ]\n",
    ")\n",
    "\n",
    "grid_search = GridSearchCV(estimator=pipeline, param_grid=models[0][\"params\"], n_jobs=-1, cv=2, verbose=2)\n",
    "grid_search.fit(X_train, y_train_encoded)\n",
    "# y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "# print(\"Accuracy score\", accuracy_score(y_test_encoded, y_pred))\n",
    "\n",
    "print(\"Model trained and ready to roll!\")\n",
    "\n",
    "selected_skills = select_skills(data_with_jobs_classified, skill_cols)\n",
    "\n",
    "if selected_skills:\n",
    "    input_vector = []\n",
    "    for skill in skill_cols:\n",
    "        if skill in selected_skills:\n",
    "            input_vector.append(1)\n",
    "        else:\n",
    "            input_vector.append(0)\n",
    "    \n",
    "    # input_array = np.array(input_vector).reshape(1, -1)\n",
    "    input_array = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "    predicted_label_encoded = grid_search.best_estimator_.predict(input_array)[0]\n",
    "    predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "    print(f\"Predicted category encoded: {predicted_label_encoded}\")\n",
    "    print(f\"Predicted category: {predicted_label}\")\n",
    "else:\n",
    "    print(\"You don't write any skill. End program.\")\n",
    "\n",
    "print(\"Accuracy score\", accuracy_score(y_test_encoded, y_pred))\n",
    "# Flask, Django, Docker, Cloud, AWS, API\n",
    "# input_vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript     \n",
    "# input_vector [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "\n",
    "# Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "# Accuracy score 0.9920634920634921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b0684c7-ce43-4bf3-aadb-8df301c32d33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "045f92a8-aff0-47e5-ad26-1a0558c62d18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "\n",
    "results = []\n",
    "\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "\n",
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "\n",
    "if not isinstance(skill_cols, list):\n",
    "    print(f\"skill_cols is not a list of skill names! Zmiana z {type(skill_cols)} na listę!\")\n",
    "    skill_cols = list(skill_cols)  \n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "\n",
    "def select_skills(data, available_skills):\n",
    "    # Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "    # selected_names = input(\"Please write skills, separated by commas (e.g.. Python,SQL,Excel): \")\n",
    "    selected_names = \"Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\"\n",
    "    print(\"selected_names\", selected_names)\n",
    "    print(\"type(selected_names)\", type(selected_names))\n",
    "    selected_skills = [name.strip() for name in selected_names.split(\",\")]\n",
    "    not_in_db_skills = [skill for skill in selected_skills if skill not in available_skills]\n",
    "    return selected_skills\n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# print(type(y_train))\n",
    "# print(type(y_test))\n",
    "# original_columns_names = set(pd.concat([y_train, y_test]))\n",
    "# print(\"original_columns_names\", original_columns_names)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "# print(\"label_encoder\", label_encoder.classes_)\n",
    "original_labels = []\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    print(f\" {i}: {label}\")\n",
    "    original_labels.append({label: i})\n",
    "\n",
    "# print(\"original_labels\", original_labels)\n",
    "\n",
    "MODELS_MAP = {\n",
    "    \"LogisticRegression\": LogisticRegression,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier,\n",
    "    \"XGBClassifier\": XGBClassifier,\n",
    "    \"XGBRFClassifier\": XGBRFClassifier,\n",
    "    \"LinearSVC\": LinearSVC,\n",
    "    \"SVC\": SVC\n",
    "}\n",
    "\n",
    "models = [\n",
    "   {\n",
    "        \"classifier\": \"LogisticRegression\",\n",
    "        \"params\": {\n",
    "            \"model__penalty\": [\"elasticnet\"],\n",
    "            \"model__C\": [0.1, 1, 0.3],\n",
    "            \"model__max_iter\": np.arange(150, 300, 150),\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__solver\": ['saga'],\n",
    "            \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"RandomForestClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200, 100],\n",
    "            # 'model__max_depth': [10, 20, None],\n",
    "            'model__max_depth': [10, None],\n",
    "            'model__min_samples_split': [2, 3],\n",
    "            # 'model__min_samples_split': [2, 3, 4, 5],\n",
    "            'model__min_samples_leaf': [1, 2, 4],\n",
    "            'model__max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"KNeighborsClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_neighbors': [3, 5, 10, 15],\n",
    "            'model__weights': ['uniform', 'distance'],\n",
    "            'model__metric': ['minkowski', 'euclidean'],\n",
    "            'model__p': [1, 2],\n",
    "            'model__algorithm': ['auto', 'ball_tree']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"XGBClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [3, 5],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            # 'model__reg_alpha': [0, 0.1, 1, 10],\n",
    "            # 'model__reg_lambda': [0, 0.1, 1, 10]\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [0, 0.1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"XGBRFClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [200, 300],\n",
    "            'model__max_depth': [5, 7, 10],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"LinearSVC\",\n",
    "        \"params\": {\n",
    "            'model__C': [0.01, 0.1, 1, 10],\n",
    "            'model__loss': ['hinge', 'squared_hinge'],\n",
    "            'model__penalty': ['l2'],\n",
    "            'model__dual': [True],\n",
    "            'model__max_iter': [1000, 5000]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"SVC\",\n",
    "        \"params\": {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'model__gamma': ['scale', 'auto', 0.1],\n",
    "            'model__degree': [2, 3],\n",
    "            'model__coef0': [0.0, 0.5]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "stop_flag = 0\n",
    "for model_config in models:\n",
    "    stop_flag = stop_flag + 1\n",
    "    if stop_flag == 2:\n",
    "        break;\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"model\", MODELS_MAP[model_config[\"classifier\"]]())\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=model_config[\"params\"], n_jobs=-1, cv=2, verbose=0)\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    classification_scores_dict = classification_report(y_test_encoded, y_pred, output_dict=True)\n",
    "    classification_scores_dict_df = pd.DataFrame(classification_scores_dict).transpose()\n",
    "    # print(\"classification_scores_dict_df\", classification_scores_dict_df)\n",
    "    # print(\"report_df\", report_df)\n",
    "    print(\"Accuracy score\", accuracy)\n",
    "    classes = np.unique(y_test_encoded)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for c in classes:\n",
    "        y_true_binary = (y_test_encoded == c).astype(int)\n",
    "        y_pred_binary = (y_test_encoded == c).astype(int)\n",
    "        \n",
    "        precision = precision_score(y_true_binary, y_pred_binary)\n",
    "        precision_scores.append(round(precision, 3))\n",
    "        recall = recall_score(y_true_binary, y_pred_binary)\n",
    "        recall_scores.append(round(recall, 3))\n",
    "        f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "        f1_scores.append(round(f1, 3))\n",
    "        \n",
    "        # print(f\"Klasa: {c}\")\n",
    "        # print(f\"Precision: {precision}\")\n",
    "        # print(f\"Recall: {recall}\")\n",
    "        # print(f\"F1-score: {f1}\")\n",
    "\n",
    "    print(\"precision_scores\", precision_scores)\n",
    "    print(\"recall_scores\", recall_scores)\n",
    "    print(\"f1_scores\", f1_scores)\n",
    "    print(\"Model trained and ready to roll!\")\n",
    "    \n",
    "    selected_skills = select_skills(data_with_jobs_classified, skill_cols)\n",
    "    \n",
    "    if selected_skills:\n",
    "        input_vector = []\n",
    "        for skill in skill_cols:\n",
    "            if skill in selected_skills:\n",
    "                input_vector.append(1)\n",
    "            else:\n",
    "                input_vector.append(0)\n",
    "        \n",
    "        # input_array = np.array(input_vector).reshape(1, -1)\n",
    "        input_array = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "        predicted_label_encoded = grid_search.best_estimator_.predict(input_array)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "        print(f\"Predicted category encoded: {predicted_label_encoded}\")\n",
    "        print(f\"Predicted category: {predicted_label}\")\n",
    "\n",
    "        model_data = {\n",
    "            \"name\": model_config[\"classifier\"],\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "            \"best_estimator\": grid_search.best_estimator_,\n",
    "            \"accuracy_score\": accuracy,\n",
    "            \"precision_scores\": precision_scores,\n",
    "            \"recall_scores\": recall_scores,\n",
    "            \"f1_scores\": f1_scores,\n",
    "            \"predicted_label\": predicted_label,\n",
    "            \"predicted_label_encoded\": predicted_label_encoded,\n",
    "            \"classification_scores\": classification_scores_dict_df,\n",
    "            \"original_labels\": original_labels\n",
    "            # \"original_labels\": label_encoder.inverse_transform(set(y_train))\n",
    "        }\n",
    "        results.append(model_data)\n",
    "    else:\n",
    "        print(\"You don't write any skill. End program.\")\n",
    "    print(\"=\"*130)\n",
    "    \n",
    "print(\"=\"*80, \"RESULTS\", \"=\"*80)\n",
    "for model in results:\n",
    "    print(f\"\"\"\n",
    "    Model name:         {model[\"name\"]}\n",
    "    Accuracy:           {model[\"accuracy_score\"]}\n",
    "    Precision:          {model[\"precision_scores\"]}\n",
    "    F1:                 {model[\"f1_scores\"]}\n",
    "    Recall:             {model[\"recall_scores\"]}\n",
    "    Predicted label:    {model[\"predicted_label\"]}\n",
    "    Predicted label:    {model[\"predicted_label_encoded\"]}\n",
    "    Original labels:    {model[\"original_labels\"]}\n",
    "\"\"\")\n",
    "    print(\"=\" * 168)\n",
    "     # Original labels:    {model[\"original_labels\"]}\n",
    "models_results_df = pd.DataFrame(data=results)\n",
    "print(models_results_df)\n",
    "type(models_results_df[\"recall_scores\"].reset_index())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Flask, Django, Docker, Cloud, AWS, API\n",
    "# input_vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript     \n",
    "# input_vector [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "\n",
    "# Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "# Accuracy score 0.9920634920634921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c99882-33e3-42c1-9dc1-df37ef78ac06",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from xgboost import XGBClassifier, XGBRFClassifier\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, precision_score, recall_score, f1_score\n",
    "from sklearn.svm import LinearSVC, NuSVC, SVC\n",
    "\n",
    "results = []\n",
    "\n",
    "# data_with_jobs_classified = pd.read_csv(\"dane_sklasyfikowane.csv\")\n",
    "# data_with_jobs_classified = copied_all_data_df.copy()\n",
    "# data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"] != \"Other\"]\n",
    "\n",
    "data_with_jobs_classified = copied_all_data_df.copy()\n",
    "counts = data_with_jobs_classified[\"skills_classified_title\"].value_counts()\n",
    "print(counts)\n",
    "values_to_keep = counts[counts > 1].index\n",
    "data_with_jobs_classified = data_with_jobs_classified[data_with_jobs_classified[\"skills_classified_title\"].isin(values_to_keep)]\n",
    "print(values_to_keep)\n",
    "\n",
    "skill_cols = data_with_jobs_classified.iloc[:, 9:]\n",
    "\n",
    "if not isinstance(skill_cols, list):\n",
    "    print(f\"skill_cols is not a list of skill names! Zmiana z {type(skill_cols)} na listę!\")\n",
    "    skill_cols = list(skill_cols)  \n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "\n",
    "def select_skills(data, available_skills):\n",
    "    # Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "    # selected_names = input(\"Please write skills, separated by commas (e.g.. Python,SQL,Excel): \")\n",
    "    selected_names = \"Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\"\n",
    "    print(\"selected_names\", selected_names)\n",
    "    print(\"type(selected_names)\", type(selected_names))\n",
    "    selected_skills = [name.strip() for name in selected_names.split(\",\")]\n",
    "    not_in_db_skills = [skill for skill in selected_skills if skill not in available_skills]\n",
    "    return selected_skills\n",
    "\n",
    "X = data_with_jobs_classified[skill_cols]\n",
    "y = data_with_jobs_classified[\"skills_classified_title\"]\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "y_train_encoded = label_encoder.fit_transform(y_train)\n",
    "y_test_encoded = label_encoder.transform(y_test)\n",
    "# print(\"label_encoder\", label_encoder.classes_)\n",
    "original_labels = []\n",
    "for i, label in enumerate(label_encoder.classes_):\n",
    "    original_labels.append({label: i})\n",
    "\n",
    "# print(\"original_labels\", original_labels)\n",
    "\n",
    "MODELS_MAP = {\n",
    "    \"LogisticRegression\": LogisticRegression,\n",
    "    \"RandomForestClassifier\": RandomForestClassifier,\n",
    "    \"KNeighborsClassifier\": KNeighborsClassifier,\n",
    "    \"XGBClassifier\": XGBClassifier,\n",
    "    \"XGBRFClassifier\": XGBRFClassifier,\n",
    "    \"LinearSVC\": LinearSVC,\n",
    "    \"SVC\": SVC\n",
    "}\n",
    "\n",
    "models = [\n",
    "   {\n",
    "        \"classifier\": \"LogisticRegression\",\n",
    "        \"params\": {\n",
    "            \"model__penalty\": [\"elasticnet\"],\n",
    "            \"model__C\": [0.1, 1, 0.3],\n",
    "            \"model__max_iter\": np.arange(150, 300, 150),\n",
    "            \"model__n_jobs\": [-1],\n",
    "            \"model__solver\": ['saga'],\n",
    "            \"model__l1_ratio\": np.arange(0.1, 1, 0.3),\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"RandomForestClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200, 100],\n",
    "            # 'model__max_depth': [10, 20, None],\n",
    "            'model__max_depth': [10, None],\n",
    "            'model__min_samples_split': [2, 3],\n",
    "            # 'model__min_samples_split': [2, 3, 4, 5],\n",
    "            'model__min_samples_leaf': [1, 2, 4],\n",
    "            'model__max_features': ['sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"KNeighborsClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_neighbors': [3, 5, 10, 15],\n",
    "            'model__weights': ['uniform', 'distance'],\n",
    "            'model__metric': ['minkowski', 'euclidean'],\n",
    "            'model__p': [1, 2],\n",
    "            'model__algorithm': ['auto', 'ball_tree']\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"XGBClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [100, 200],\n",
    "            'model__max_depth': [3, 5],\n",
    "            'model__learning_rate': [0.05, 0.1],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            # 'model__reg_alpha': [0, 0.1, 1, 10],\n",
    "            # 'model__reg_lambda': [0, 0.1, 1, 10]\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [0, 0.1]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"XGBRFClassifier\",\n",
    "        \"params\": {\n",
    "            'model__n_estimators': [200, 300],\n",
    "            'model__max_depth': [5, 7, 10],\n",
    "            'model__subsample': [0.8, 1.0],\n",
    "            'model__colsample_bytree': [0.8, 1.0],\n",
    "            'model__reg_alpha': [0, 0.1],\n",
    "            'model__reg_lambda': [1, 10]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"LinearSVC\",\n",
    "        \"params\": {\n",
    "            'model__C': [0.01, 0.1, 1, 10],\n",
    "            'model__loss': ['hinge', 'squared_hinge'],\n",
    "            'model__penalty': ['l2'],\n",
    "            'model__dual': [True],\n",
    "            'model__max_iter': [1000, 5000]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"classifier\": \"SVC\",\n",
    "        \"params\": {\n",
    "            'model__C': [0.1, 1, 10],\n",
    "            'model__kernel': ['linear', 'rbf', 'poly'],\n",
    "            'model__gamma': ['scale', 'auto', 0.1],\n",
    "            'model__degree': [2, 3],\n",
    "            'model__coef0': [0.0, 0.5]\n",
    "        }\n",
    "    },\n",
    "]\n",
    "\n",
    "stop_flag = 0\n",
    "for model_config in models:\n",
    "    # stop_flag = stop_flag + 1\n",
    "    # if stop_flag == 2:\n",
    "    #     break;\n",
    "    \n",
    "    pipeline = Pipeline(\n",
    "        steps=[\n",
    "            (\"model\", MODELS_MAP[model_config[\"classifier\"]]())\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    grid_search = GridSearchCV(estimator=pipeline, param_grid=model_config[\"params\"], n_jobs=-1, cv=2, verbose=0)\n",
    "    grid_search.fit(X_train, y_train_encoded)\n",
    "    y_pred = grid_search.best_estimator_.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test_encoded, y_pred)\n",
    "    print(\"model_config['classifier']\", model_config[\"classifier\"])\n",
    "    print(\"accuracy\", accuracy)\n",
    "    classification_scores_dict = classification_report(y_test_encoded, y_pred, output_dict=True)\n",
    "    classification_scores_dict_df = pd.DataFrame(classification_scores_dict).transpose()\n",
    "    # print(\"classification_scores_dict_df\", classification_scores_dict_df)\n",
    "    # print(\"report_df\", report_df)\n",
    "    classes = np.unique(y_test_encoded)\n",
    "    precision_scores = []\n",
    "    recall_scores = []\n",
    "    f1_scores = []\n",
    "\n",
    "    for c in classes:\n",
    "        y_true_binary = (y_test_encoded == c).astype(int)\n",
    "        y_pred_binary = (y_test_encoded == c).astype(int)\n",
    "        \n",
    "        precision = precision_score(y_true_binary, y_pred_binary)\n",
    "        precision_scores.append(round(precision, 3))\n",
    "        recall = recall_score(y_true_binary, y_pred_binary)\n",
    "        recall_scores.append(round(recall, 3))\n",
    "        f1 = f1_score(y_true_binary, y_pred_binary)\n",
    "        f1_scores.append(round(f1, 3))\n",
    "\n",
    "    print(\"Model trained and ready to roll!\")\n",
    "    \n",
    "    selected_skills = select_skills(data_with_jobs_classified, skill_cols)\n",
    "    \n",
    "    if selected_skills:\n",
    "        input_vector = []\n",
    "        for skill in skill_cols:\n",
    "            if skill in selected_skills:\n",
    "                input_vector.append(1)\n",
    "            else:\n",
    "                input_vector.append(0)\n",
    "        \n",
    "        # input_array = np.array(input_vector).reshape(1, -1)\n",
    "        input_array = pd.DataFrame([input_vector], columns=skill_cols)\n",
    "        predicted_label_encoded = grid_search.best_estimator_.predict(input_array)[0]\n",
    "        predicted_label = label_encoder.inverse_transform([predicted_label_encoded])[0]\n",
    "        print(f\"Predicted category encoded: {predicted_label_encoded}\")\n",
    "        print(f\"Predicted category: {predicted_label}\")\n",
    "\n",
    "        model_data = {\n",
    "            \"name\": model_config[\"classifier\"],\n",
    "            \"best_params\": grid_search.best_params_,\n",
    "            \"best_estimator\": grid_search.best_estimator_,\n",
    "            \"accuracy_score\": accuracy,\n",
    "            \"precision_scores\": precision_scores,\n",
    "            \"recall_scores\": recall_scores,\n",
    "            \"f1_scores\": f1_scores,\n",
    "            \"predicted_label\": predicted_label,\n",
    "            \"predicted_label_encoded\": predicted_label_encoded,\n",
    "            \"classification_scores\": classification_scores_dict_df,\n",
    "            \"original_labels\": original_labels\n",
    "        }\n",
    "        results.append(model_data)\n",
    "    else:\n",
    "        print(\"You don't write any skill. End program.\")\n",
    "    print(\"=\"*130)\n",
    "    \n",
    "print(\"=\"*80, \"RESULTS\", \"=\"*80)\n",
    "for model in results:\n",
    "    print(f\"\"\"\n",
    "    Model name:         {model[\"name\"]}\n",
    "    Accuracy:           {model[\"accuracy_score\"]}\n",
    "    Precision:          {model[\"precision_scores\"]}\n",
    "    F1:                 {model[\"f1_scores\"]}\n",
    "    Recall:             {model[\"recall_scores\"]}\n",
    "    Predicted label:    {model[\"predicted_label\"]}\n",
    "    Predicted label:    {model[\"predicted_label_encoded\"]}\n",
    "    Original labels:    {model[\"original_labels\"]}\n",
    "\"\"\")\n",
    "    print(\"=\" * 168)\n",
    "\n",
    "models_results_df = pd.DataFrame(data=results)\n",
    "list_columns = ['precision_scores', 'recall_scores', 'f1_scores']\n",
    "\n",
    "for col in list_columns:\n",
    "    expanded_cols = pd.DataFrame(models_results_df[col].tolist())\n",
    "    expanded_cols = expanded_cols.add_prefix(f'{col}_')\n",
    "    models_results_df = pd.concat([models_results_df, expanded_cols], axis=1)\n",
    " \n",
    "columns_to_show=['name', 'accuracy_score','predicted_label',\n",
    "       'predicted_label_encoded',\n",
    "       'precision_scores_0', 'precision_scores_1', 'precision_scores_2',\n",
    "       'precision_scores_3', 'recall_scores_0', 'recall_scores_1',\n",
    "       'recall_scores_2', 'recall_scores_3', 'f1_scores_0', 'f1_scores_1',\n",
    "       'f1_scores_2', 'f1_scores_3']\n",
    "\n",
    "models_results_df.columns\n",
    "models_results_df[columns_to_show]\n",
    "# Flask, Django, Docker, Cloud, AWS, API\n",
    "# input_vector [0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0,\n",
    "\n",
    "# AI, Docker, English, HTML5 / CSS3, Javascript, Node.js, Typescript     \n",
    "# input_vector [0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
    "\n",
    "# Pandas, Numpy, Matplotlib, Data, Analyzing, Data Storage\n",
    "# Accuracy score 0.9920634920634921"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c763d7c-e9ec-4dc1-97c3-7b240d625d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "models_results_df[columns_to_show]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c97f0e-8731-4b41-a651-942a09be6ca8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b84ffcc9-eaca-439d-8fe2-23df7121e9ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
